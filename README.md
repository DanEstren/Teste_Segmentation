# FastSAM Auto-Annotator ğŸ¯

Uma ferramenta **Human-in-the-loop** para criaÃ§Ã£o acelerada de datasets de segmentaÃ§Ã£o. O usuÃ¡rio seleciona a regiÃ£o de interesse (Bounding Box) no frontend, e o backend utiliza o **FastSAM (Segment Anything Model)** para gerar mÃ¡scaras de segmentaÃ§Ã£o precisas, convertendo-as automaticamente para o sistema de coordenadas da imagem original.

## ğŸš€ Funcionalidades

* **SeleÃ§Ã£o Interativa:** Interface Web simples para desenhar Bounding Boxes sobre imagens.
* **SegmentaÃ§Ã£o Assistida por IA:** Utiliza o modelo `FastSAM-s.pt` (ou `yolov8-seg`) para segmentar objetos dentro do crop.
* **Mapeamento de Coordenadas:** Algoritmo inteligente que traduz a mÃ¡scara do "crop" de volta para a resoluÃ§Ã£o original da imagem.
* **Dataset Ready:** Salva automaticamente:
* Imagem original em `dataset/images/`
* Labels no formato YOLO Segmentation em `dataset/labels/`



## ğŸ› ï¸ Arquitetura e LÃ³gica

O diferencial deste projeto Ã© a preservaÃ§Ã£o da resoluÃ§Ã£o. Ao invÃ©s de redimensionar a imagem inteira para a entrada da IA (o que causaria perda de detalhes em objetos pequenos), o sistema funciona assim:

1. **Crop:** O Frontend envia apenas as coordenadas e a imagem original.
2. **Inference:** O Backend recorta a imagem em alta resoluÃ§Ã£o.
3. **Segmentation:** O FastSAM processa apenas o recorte (maximiza a densidade de pixels).
4. **Recalculation:** As coordenadas da mÃ¡scara  sÃ£o convertidas para  usando o offset do crop:



## ğŸ“¦ Estrutura do Projeto

```bash
meu_projeto/
â”‚
â”œâ”€â”€ dataset/             # Dados gerados (ignorado no git)
â”‚   â”œâ”€â”€ images/          # Imagens originais salvas
â”‚   â””â”€â”€ labels/          # Arquivos .txt com segmentaÃ§Ã£o YOLO
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html       # Frontend (Canvas + JS)
â”‚
â”œâ”€â”€ weights/             # Pesos do modelo
â”‚   â””â”€â”€ FastSAM-s.pt     # (Baixado automaticamente ou manual)
â”‚
â”œâ”€â”€ main.py              # Backend FastAPI
â”œâ”€â”€ requirements.txt     # DependÃªncias
â””â”€â”€ README.md            # DocumentaÃ§Ã£o

```

## ğŸ”§ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/fastsam-annotator.git
cd fastsam-annotator

```

### 2. Crie um ambiente virtual (Recomendado)

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate

```

### 3. Instale as dependÃªncias

Crie um arquivo `requirements.txt` com o conteÃºdo abaixo e instale:

```text
fastapi
uvicorn
python-multipart
opencv-python
ultralytics
supervision
numpy

```

```bash
pip install -r requirements.txt

```

### 4. Baixe o Modelo

O cÃ³digo baixarÃ¡ automaticamente o `FastSAM-s.pt` na primeira execuÃ§Ã£o, ou vocÃª pode baixÃ¡-lo manualmente e colocar na raiz.

## â–¶ï¸ Como Usar

1. **Inicie o Servidor:**
```bash
uvicorn main:app --reload

```


2. **Acesse a Interface:**
Abra o navegador em `http://127.0.0.1:8000/static/index.html`.
3. **Fluxo de Trabalho:**
* Clique em "Escolher arquivo" e carregue uma imagem.
* Desenhe um retÃ¢ngulo vermelho ao redor do objeto que deseja segmentar.
* Clique em **"Enviar Crop para Segmentar"**.
* Verifique a pasta `dataset/labels/` para ver o arquivo `.txt` gerado.



## âš™ï¸ ConfiguraÃ§Ã£o do Modelo (Main.py)

No arquivo `main.py`, vocÃª pode alternar entre modelos dependendo da necessidade:

```python
# Para objetos genÃ©ricos (Recomendado)
from ultralytics import FastSAM
model = FastSAM('FastSAM-s.pt')

# Para objetos comuns (COCO Dataset: Carro, Pessoa, etc.)
# from ultralytics import YOLO
# model = YOLO('yolov8n-seg.pt')

```

## ğŸ“ Formato de SaÃ­da (Labels)

Os arquivos `.txt` sÃ£o salvos no formato padrÃ£o YOLO Segmentation:

```text
<class_id> <x1> <y1> <x2> <y2> ... <xn> <yn>

```

* Tudo normalizado entre 0 e 1.
* `class_id` padrÃ£o Ã© `0`.

## ğŸ¤ ContribuiÃ§Ã£o

Sinta-se Ã  vontade para abrir Issues ou Pull Requests para melhorar a interface do frontend ou adicionar suporte a mÃºltiplas classes.

---

**Desenvolvido com FastAPI e Ultralytics.**
